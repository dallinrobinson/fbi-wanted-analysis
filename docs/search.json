[
  {
    "objectID": "TechnicalReport.html",
    "href": "TechnicalReport.html",
    "title": "Technical Report: FBI Wanted Analysis",
    "section": "",
    "text": "This project analyzes publicly available data from the FBI Wanted API to examine patterns in active wanted-person listings. The analysis focuses on four research questions: how the quantity of wanted cases changes over time, which geographic areas have the highest concentration of cases, which types of crimes receive the largest rewards, and what the joint trends in case counts and rewards reveal about law enforcement priorities. Using a reproducible Python-based pipeline and an interactive Streamlit dashboard, the results suggest that reward size reflects case severity and strategic importance rather than case volume alone, while geographic concentration varies substantially across FBI field offices."
  },
  {
    "objectID": "TechnicalReport.html#executive-summary",
    "href": "TechnicalReport.html#executive-summary",
    "title": "Technical Report: FBI Wanted Analysis",
    "section": "",
    "text": "This project analyzes publicly available data from the FBI Wanted API to examine patterns in active wanted-person listings. The analysis focuses on four research questions: how the quantity of wanted cases changes over time, which geographic areas have the highest concentration of cases, which types of crimes receive the largest rewards, and what the joint trends in case counts and rewards reveal about law enforcement priorities. Using a reproducible Python-based pipeline and an interactive Streamlit dashboard, the results suggest that reward size reflects case severity and strategic importance rather than case volume alone, while geographic concentration varies substantially across FBI field offices."
  },
  {
    "objectID": "TechnicalReport.html#project-context",
    "href": "TechnicalReport.html#project-context",
    "title": "Technical Report: FBI Wanted Analysis",
    "section": "Project Context",
    "text": "Project Context\nThe FBI Wanted list serves as a public-facing tool for enlisting assistance in locating individuals associated with serious federal crimes. Understanding how listings are distributed across time, geography, and crime type provides insight into enforcement priorities and resource allocation. Stakeholders for this analysis include policymakers, researchers, and the general public interested in crime patterns and federal enforcement strategy. Success is measured by producing transparent, reproducible summaries that accurately reflect the structure and limitations of the underlying data."
  },
  {
    "objectID": "TechnicalReport.html#data-sources",
    "href": "TechnicalReport.html#data-sources",
    "title": "Technical Report: FBI Wanted Analysis",
    "section": "Data Sources",
    "text": "Data Sources\n\nPrimary dataset:\nFBI Wanted API\nhttps://api.fbi.gov/wanted/v1/list\nSupplementary data:\nNone (analysis relies solely on fields provided by the FBI API)\nData access notes:\nThe API provides current active listings only and does not expose historical snapshots of the wanted list. As a result, analyses of historical change rely on publication dates or require externally stored snapshots for true longitudinal analysis. There is no API key required for access."
  },
  {
    "objectID": "TechnicalReport.html#methodology",
    "href": "TechnicalReport.html#methodology",
    "title": "Technical Report: FBI Wanted Analysis",
    "section": "Methodology",
    "text": "Methodology\n\nData acquisition\nData are retrieved programmatically using HTTP requests to the FBI Wanted API. Pagination is handled to collect multiple pages of results in a single pull. Our process creates 22 pages of data.\nCleaning pipeline\nRaw JSON responses are normalized into a tabular format. Relevant fields (e.g., publication date, field office, subjects, reward text) are retained, dates are parsed into datetime objects, and reward information is extracted into numeric indicators where possible.\nAnalysis workflow\n\nQuantity over time: Listings are aggregated by publication month and year to describe when currently active cases were posted.\n\nGeographic concentration: Listings are grouped by FBI field office and summarized using counts and shares of total listings. There are many entries with no field office associated.\nCrime type and rewards: Listings with numeric reward amounts are exploded by subject tags and summarized using median, mean, and maximum rewards.\n\nPriority interpretation: Joint patterns in listing counts and reward magnitudes are used to infer enforcement focus and case severity.\n\nTooling\n\nPython (pandas, requests) for data processing\n\nStreamlit for interactive visualization\n\nGit/GitHub for version control and reproducibility\n\nVirtual environment for dependency management\n\n\n\n\n\nFBI Wanted Analysis – Data Processing Sequence"
  },
  {
    "objectID": "TechnicalReport.html#results-diagnostics",
    "href": "TechnicalReport.html#results-diagnostics",
    "title": "Technical Report: FBI Wanted Analysis",
    "section": "Results & Diagnostics",
    "text": "Results & Diagnostics\nThe analysis shows that:\n\nPublication dates of active listings cluster in certain periods, indicating bursts of new postings rather than a steady flow.\nA small number of FBI field offices account for a disproportionately large share of active wanted cases.\nThere are a large number of fugitives with no associated field office, this is because they are international, elusive, or their crimes cross multiples jurisdictions.\nCrime types related to terrorism, violent crime, and national security receive substantially higher median reward amounts than other categories.\nHigher rewards are not associated with a larger number of cases, suggesting that reward size reflects case severity and difficulty rather than frequency.\n\nAll summary tables and figures are generated directly from the cleaned dataset and displayed in the Streamlit dashboard."
  },
  {
    "objectID": "TechnicalReport.html#discussion-next-steps",
    "href": "TechnicalReport.html#discussion-next-steps",
    "title": "Technical Report: FBI Wanted Analysis",
    "section": "Discussion & Next Steps",
    "text": "Discussion & Next Steps\nThese findings suggest that FBI reward structures emphasize prioritization of high-risk or high-impact cases rather than broad coverage. However, the analysis is limited by the lack of historical snapshots of the wanted list; true longitudinal conclusions about changes in enforcement focus require archived or regularly collected snapshots over time. Future work could incorporate Wayback Machine data or scheduled data collection to enable a fully historical analysis, as well as external data sources to contextualize findings by population or crime rates. For this project, usage of the Wayback Machine was considered, however, it was deemed too challenging to implement in an efficient way for a Stat386 student. The process of scraping data was achievable, but it would require manual entries of the URLs for each fugitive rather than the utilizing the pagination system used in the API data gathering."
  },
  {
    "objectID": "Documentation.html",
    "href": "Documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "This document describes the purpose, inputs, outputs, and expected usage of the functions in analysis.py for the FBI Wanted Analysis project."
  },
  {
    "objectID": "Documentation.html#functions",
    "href": "Documentation.html#functions",
    "title": "Documentation",
    "section": "Functions",
    "text": "Functions\n\nfetch_current_wanted(page_size: int = 200, pages: int = 1) -&gt; pd.DataFrame\nPurpose\nFetches current FBI Wanted listings from the FBI Wanted API and returns a normalized pandas DataFrame containing a subset of high-value fields used throughout the project.\nInputs - page_size (int): Number of records per page requested from the API (default 200). - pages (int): Number of pages to fetch (default 1).\nOutput - pd.DataFrame: DataFrame of wanted listings. If the API returns no items, returns an empty DataFrame.\nKey columns returned (if available) - uid, title, publication, field_offices, sex, race, subjects, reward_text, caution, details\nNotes - This function returns current listings only. The FBI API endpoint used does not provide historical snapshots.\n\n\n\nrun_analysis_pipeline() -&gt; None\nPurpose\nLegacy stub included to prevent older scaffolding/tests from breaking.\nInputs / Outputs - No inputs. Prints a short message."
  },
  {
    "objectID": "Documentation.html#research-question-functions",
    "href": "Documentation.html#research-question-functions",
    "title": "Documentation",
    "section": "Research Question Functions",
    "text": "Research Question Functions\n\nRQ1 — quantity_over_time(df: pd.DataFrame) -&gt; pd.DataFrame\nResearch question\nHow does the quantity of most wanted cases change over time?\nPurpose\nAggregates listings by snapshot_date and counts unique listings per snapshot. This function is intended for a snapshot-based dataset.\nRequired columns in df - snapshot_date (datetime-like): The date/time the snapshot was captured. - uid (str): Unique listing identifier.\nOutput - pd.DataFrame with columns: - snapshot_date - total_listings (unique uid count per snapshot)\nInterpretation - Each row represents a snapshot date, with total_listings equal to the number of active listings observed in that snapshot.\nImportant limitation - This function requires snapshot data. The current FBI API pull does not include snapshot_date unless you add it externally (e.g., scheduled pulls or archived snapshots).\n\n\n\nRQ2 — geographic_concentration_over_time(df: pd.DataFrame, geography: str) -&gt; pd.DataFrame\nResearch question\nWhich U.S regions, states, or FBI field offices have the highest concentration of wanted cases? How has this distribution shifted historically?\nPurpose\nComputes concentration (counts and shares) by a specified geographic dimension for each snapshot_date.\nInputs - df (pd.DataFrame): Snapshot-based dataset. - geography (str): Column name in df representing the geography to analyze (e.g., \"field_offices\", \"state\", \"region\").\nRequired columns in df - snapshot_date - uid - geography (column specified by the geography argument)\nOutput - pd.DataFrame with columns: - snapshot_date - &lt;geography&gt; (the chosen category column) - listings (unique listing count per category per snapshot) - share (listings divided by total listings for that snapshot)\nInterpretation - share allows comparisons across time even if the total number of listings changes.\nImportant limitation - As written, the function assumes true snapshot data is available via snapshot_date.\n\n\n\nRQ3 — reward_by_crime_type(df: pd.DataFrame) -&gt; pd.DataFrame\nResearch question\nWhat types of crimes receive the highest reward amounts?\nPurpose\nSummarizes reward amounts by crime “type” using the subjects field as the crime-type label. Subject lists are exploded so each listing can contribute to multiple categories without double-counting within a category.\nRequired columns in df - uid - subjects (list-like or str): Crime-type tags - reward_has_amount (bool): Indicates whether a numeric reward amount was parsed - reward_amount_max_usd (numeric): Maximum stated reward in USD (parsed)\nOutput - pd.DataFrame with columns: - crime_type - median_reward - mean_reward - max_reward - listings (number of (uid, crime_type) pairs contributing)\nInterpretation - median_reward is typically the most robust summary for comparing crime types because reward distributions can be highly skewed."
  },
  {
    "objectID": "Documentation.html#helpers",
    "href": "Documentation.html#helpers",
    "title": "Documentation",
    "section": "Helpers",
    "text": "Helpers\n\n_to_datetime_series(s: pd.Series) -&gt; pd.Series\nPurpose\nSafely converts a series to datetime using errors=\"coerce\" and utc=True.\nInput - s (pd.Series)\nOutput - pd.Series of datetimes (invalid parses become NaT)\n\n\n\n_add_time_grain(df: pd.DataFrame, date_col: str, freq: str = \"M\") -&gt; pd.DataFrame\nPurpose\nAdds a period column that bins a datetime column into a specified frequency (day/week/month/quarter/year), then converts it to a timestamp (start of period).\nInputs - df (pd.DataFrame) - date_col (str): Name of date column to transform (commonly \"publication\") - freq (str): Pandas period frequency (default \"M\")\nOutput - Copy of df with a new period column.\nNotes - If date_col is missing, period is set to NaT.\n\n\n\n_safe_first_subject(x) -&gt; str\nPurpose\nReturns the first subject tag if available; otherwise returns \"Unknown\".\n\n\n\n_ensure_reward_cols(df: pd.DataFrame) -&gt; None\nPurpose\nValidates that reward parsing columns exist (expected to be created during cleaning). Raises a clear error if missing.\nRequired reward columns - reward_has_text - reward_has_amount - reward_amount_max_usd - reward_program"
  },
  {
    "objectID": "Documentation.html#rq4-priorityinterpretation-functions",
    "href": "Documentation.html#rq4-priorityinterpretation-functions",
    "title": "Documentation",
    "section": "RQ4 — Priority/Interpretation Functions",
    "text": "RQ4 — Priority/Interpretation Functions\nThese functions support the interpretation question:\n\nWhat do trends in rewards and quantity of wanted persons reveal about law enforcement priorities?\n\nThey are designed to work with the current API dataset using publication as the time anchor (unless you later build true snapshots).\n\n\nrq4_volume_trend(df: pd.DataFrame, date_col: str = \"publication\", freq: str = \"M\") -&gt; pd.DataFrame\nPurpose\nComputes the number of listings over time by aggregating a date column into time periods.\nInputs - df (pd.DataFrame) - date_col (str): Date column to use (default \"publication\") - freq (str): Time bin frequency (default \"M\")\nOutput - pd.DataFrame with columns: - period - listings (count of rows per period)\nInterpretation - Shows when currently active listings were published (publication-date trend), not the historical active-list size unless snapshot data is used.\n\n\n\nrq4_reward_trend(df: pd.DataFrame, date_col: str = \"publication\", freq: str = \"M\") -&gt; pd.DataFrame\nPurpose\nSummarizes reward presence and reward magnitude over time.\nInputs - df (pd.DataFrame) - date_col (str): Date column to use (default \"publication\") - freq (str): Time bin frequency (default \"M\")\nRequired columns - publication (or chosen date_col) - reward parsing columns enforced by _ensure_reward_cols\nOutput - pd.DataFrame with columns: - period - listings - pct_with_reward_text - pct_with_numeric_reward - median_reward_max_usd - p90_reward_max_usd - max_reward_max_usd\nInterpretation - Reward percentages indicate how often rewards are used. - Median/p90/max reward show how reward magnitude changes across publication periods.\n\n\n\nrq4_priority_by_subject(df: pd.DataFrame, top_n: int = 15) -&gt; pd.DataFrame\nPurpose\nRanks subject categories using: - how often they appear, - how often they include numeric rewards, - typical reward size (median reward among numeric rewards).\nInputs - top_n (int): Number of top subjects to return.\nOutput - pd.DataFrame with columns: - subject - listings - pct_numeric_reward - median_reward_max_usd\nInterpretation - Useful for connecting “crime type” with both frequency and reward intensity.\n\n\n\nrq4_priority_by_program(df: pd.DataFrame) -&gt; pd.DataFrame\nPurpose\nSummarizes reward patterns by reward program (e.g., FBI programs vs other reward initiatives).\nOutput - pd.DataFrame with columns: - reward_program - listings_with_text - listings_with_amount - median_reward_max_usd - max_reward_max_usd\nInterpretation - Helps explain whether high rewards come from specific reward programs.\n\n\n\nrq4_priority_by_field_office(df: pd.DataFrame, top_n: int = 15) -&gt; pd.DataFrame\nPurpose\nShows which field offices have the most listings and whether those listings tend to have numeric rewards and higher reward magnitudes.\nKey behavior - Handles field_offices values that may be lists by normalizing to lists and exploding.\nOutput - pd.DataFrame with columns: - field_office - listings - pct_numeric_reward - median_reward_max_usd\nInterpretation - Useful for comparing geographic concentration with reward intensity."
  },
  {
    "objectID": "Documentation.html#recommended-usage-in-streamlit",
    "href": "Documentation.html#recommended-usage-in-streamlit",
    "title": "Documentation",
    "section": "Recommended Usage in Streamlit",
    "text": "Recommended Usage in Streamlit\nA typical workflow is:\n\nFetch + clean:\n\ndf_raw = fetch_current_wanted(...)\ndf = clean_wanted(df_raw)\n\nProduce summary tables:\n\nreward_by_crime_type(df)\nrq4_volume_trend(df)\nrq4_reward_trend(df)\nrq4_priority_by_subject(df)\nrq4_priority_by_field_office(df)\n\nVisualize:\n\nLine charts for trends (rq4_volume_trend, rq4_reward_trend)\nBar charts for top categories (reward_by_crime_type, priority tables)"
  },
  {
    "objectID": "Tutorial.html",
    "href": "Tutorial.html",
    "title": "Getting Started with fbi_wanted_analysis",
    "section": "",
    "text": "This tutorial walks you through how to install fbi_wanted_analysis, pull live data from the FBI Wanted API, clean it, and run the core analysis functions that answer the four research questions for the project.\nWe will:"
  },
  {
    "objectID": "Tutorial.html#installation",
    "href": "Tutorial.html#installation",
    "title": "Getting Started with fbi_wanted_analysis",
    "section": "1. Installation",
    "text": "1. Installation\nYou can install the package either with uv or with pip, depending on your workflow.\n\n1.1 Install with uv\nFrom a terminal in your project folder:\nuv add fbi-wanted-analysis\nuv will resolve and install:\n\nfbi-wanted-analysis\npandas\nnumpy\nrequests\nstreamlit\nand other dependencies\n\n\n\n1.2 Install with pip\nIf you prefer pip:\npip install fbi-wanted-analysis\nThen you are ready to import the package in Python or Jupyter."
  },
  {
    "objectID": "Tutorial.html#package-overview",
    "href": "Tutorial.html#package-overview",
    "title": "Getting Started with fbi_wanted_analysis",
    "section": "2. Package overview",
    "text": "2. Package overview\nThe package has three main modules:\n\nfbi_wanted_analysis.__init__\n\nRe-exports the most important entry points:\n\nfetch_current_wanted\nclean_wanted\n\n\nfbi_wanted_analysis.cleaning\n\nFunctions to clean and normalize the raw FBI API data\nApplies reward parsing from rewards.py\n\nfbi_wanted_analysis.analysis\n\nFunctions for answering the four research questions using pandas\n\n\nThe core workflow:\n\nUse fetch_current_wanted() to call the FBI Wanted API and return a raw DataFrame.\nPass that DataFrame into clean_wanted() to add parsed reward fields and normalize columns.\nUse the analysis helpers from analysis.py to create summary tables for each research question."
  },
  {
    "objectID": "Tutorial.html#first-import-and-basic-usage",
    "href": "Tutorial.html#first-import-and-basic-usage",
    "title": "Getting Started with fbi_wanted_analysis",
    "section": "3. First import and basic usage",
    "text": "3. First import and basic usage\nStart by importing from the top-level package and pulling a small sample.\n\nfrom fbi_wanted_analysis import fetch_current_wanted, clean_wanted\n\n# Pull the first page of results (50 records)\nraw = fetch_current_wanted(page_size=50, pages=1)\n\nraw.shape\n\n(50, 10)\n\n\nYou should see something like (N, K) where N is the number of rows and K is the number of columns.\nInspect the first few rows:\n\nraw.head()\n\n\n\n\n\n\n\n\nfield_offices\ndetails\ncaution\ntitle\nrace\npublication\nsubjects\nreward_text\nuid\nsex\n\n\n\n\n0\n[lasvegas]\n&lt;p&gt;The Federal Bureau of Investigation's Las V...\nNone\nDEFACEMENT OF FEDERAL PROPERTY\nNone\n2025-06-25T09:42:00\n[Seeking Information]\nThe FBI is offering a reward of up to $1,000 f...\n07f33176ac684ec19ac5a2794bdf196f\nNone\n\n\n1\n[louisville]\nNone\n&lt;p&gt;Terry Matthews is wanted for his alleged in...\nTERRY MATTHEWS\nblack\n2025-07-02T08:03:00\n[Criminal Enterprise Investigations]\nNone\nde4766a45bf4435bb3303b6da7d1febb\nMale\n\n\n2\nNone\n&lt;p&gt;In June of 2021, Celeste Doghmi was reporte...\nNone\nCELESTE DIANA DOGHMI - AUBURN, MAINE\nNone\n2025-07-02T07:26:00\n[ViCAP Missing Persons]\nNone\n5126982a11c6494fa53fb44d54c56206\nFemale\n\n\n3\n[miami]\nNone\n&lt;p&gt;Vitel'Homme Innocent, as leader of the gang...\nVITEL'HOMME INNOCENT\nblack\n2022-11-03T10:49:00\n[Additional Violent Crimes]\nThe United States Department of State’s Transn...\n466379d55d804fdeabfc3944c5d44331\nMale\n\n\n4\n[dallas]\nNone\n&lt;p&gt;Cindy Rodriguez Singh is wanted for alleged...\nCINDY RODRIGUEZ SINGH\nhispanic\n2024-07-11T13:11:00\n[Ten Most Wanted Fugitives, Case of the Week]\nThe FBI is offering a reward of up to $250,000...\nfa908b7efed64603b9f95efa0288643f\nFemale\n\n\n\n\n\n\n\nThe raw DataFrame includes columns such as:\n\nuid\ntitle\npublication (string or timestamp)\nfield_offices\nsex\nrace\nsubjects\nreward_text\ncaution\ndetails"
  },
  {
    "objectID": "Tutorial.html#cleaning-and-reward-parsing",
    "href": "Tutorial.html#cleaning-and-reward-parsing",
    "title": "Getting Started with fbi_wanted_analysis",
    "section": "4. Cleaning and reward parsing",
    "text": "4. Cleaning and reward parsing\nNext, run the cleaning pipeline. This function:\n\nConverts publication into a proper datetime\nNormalizes field_offices into a consistent string\nParses reward_text into numeric and categorical fields using parse_reward from rewards.py\n\n\nclean = clean_wanted(raw)\nclean.head()\n\n\n\n\n\n\n\n\nfield_offices\ndetails\ncaution\ntitle\nrace\npublication\nsubjects\nreward_text\nuid\nsex\nreward_text_clean\nreward_has_text\nreward_has_amount\nreward_amounts_usd\nreward_amount_min_usd\nreward_amount_max_usd\nreward_is_up_to\nreward_mentions_additional\nreward_program\n\n\n\n\n0\nlasvegas\n&lt;p&gt;The Federal Bureau of Investigation's Las V...\nNone\nDEFACEMENT OF FEDERAL PROPERTY\nNone\n2025-06-25 09:42:00\n[Seeking Information]\nThe FBI is offering a reward of up to $1,000 f...\n07f33176ac684ec19ac5a2794bdf196f\nNone\nThe FBI is offering a reward of up to $1,000 f...\nTrue\nTrue\n[1000]\n1000\n1000\nTrue\nFalse\nFBI\n\n\n1\nlouisville\nNone\n&lt;p&gt;Terry Matthews is wanted for his alleged in...\nTERRY MATTHEWS\nblack\n2025-07-02 08:03:00\n[Criminal Enterprise Investigations]\nNone\nde4766a45bf4435bb3303b6da7d1febb\nMale\n\nFalse\nFalse\n[]\n&lt;NA&gt;\n&lt;NA&gt;\nFalse\nFalse\nOther/Unknown\n\n\n2\n\n&lt;p&gt;In June of 2021, Celeste Doghmi was reporte...\nNone\nCELESTE DIANA DOGHMI - AUBURN, MAINE\nNone\n2025-07-02 07:26:00\n[ViCAP Missing Persons]\nNone\n5126982a11c6494fa53fb44d54c56206\nFemale\n\nFalse\nFalse\n[]\n&lt;NA&gt;\n&lt;NA&gt;\nFalse\nFalse\nOther/Unknown\n\n\n3\nmiami\nNone\n&lt;p&gt;Vitel'Homme Innocent, as leader of the gang...\nVITEL'HOMME INNOCENT\nblack\n2022-11-03 10:49:00\n[Additional Violent Crimes]\nThe United States Department of State’s Transn...\n466379d55d804fdeabfc3944c5d44331\nMale\nThe United States Department of State’s Transn...\nTrue\nTrue\n[2000000]\n2000000\n2000000\nTrue\nFalse\nState Department\n\n\n4\ndallas\nNone\n&lt;p&gt;Cindy Rodriguez Singh is wanted for alleged...\nCINDY RODRIGUEZ SINGH\nhispanic\n2024-07-11 13:11:00\n[Ten Most Wanted Fugitives, Case of the Week]\nThe FBI is offering a reward of up to $250,000...\nfa908b7efed64603b9f95efa0288643f\nFemale\nThe FBI is offering a reward of up to $250,000...\nTrue\nTrue\n[250000]\n250000\n250000\nTrue\nFalse\nFBI\n\n\n\n\n\n\n\nAfter cleaning, you should see additional columns such as:\n\nreward_text_clean\nreward_has_text (True/False)\nreward_has_amount (True/False)\nreward_amounts_usd (list of ints)\nreward_amount_min_usd (int or NA)\nreward_amount_max_usd (int or NA)\nreward_is_up_to (True/False)\nreward_mentions_additional (True/False)\nreward_program (for example: \"FBI\", \"Rewards for Justice\", \"Other/Unknown\")\n\nYou can quickly check the distribution of reward programs:\n\nclean[\"reward_program\"].value_counts().head()\n\nreward_program\nFBI                    26\nOther/Unknown          21\nState Department        2\nRewards for Justice     1\nName: count, dtype: int64"
  },
  {
    "objectID": "Tutorial.html#analysis-helpers-and-research-questions",
    "href": "Tutorial.html#analysis-helpers-and-research-questions",
    "title": "Getting Started with fbi_wanted_analysis",
    "section": "5. Analysis helpers and research questions",
    "text": "5. Analysis helpers and research questions\nTo run the analysis helpers, import them from the analysis module.\n\nfrom fbi_wanted_analysis.analysis import (\n    quantity_over_time,\n    geographic_concentration_over_time,\n    reward_by_crime_type,\n    rq4_volume_trend,\n    rq4_reward_trend,\n    rq4_priority_by_subject,\n    rq4_priority_by_program,\n    rq4_priority_by_field_office,\n)\n\nBelow we assume you already have a cleaned DataFrame named clean.\n\nclean = clean_wanted(fetch_current_wanted(page_size=200, pages=3))\nclean.shape\n\n(150, 19)\n\n\n\n5.1 RQ1: Volume trend over time\nResearch Question 1 &gt; How does the quantity of most wanted cases change over time?\nSimplest option: you can use rq4_volume_trend on the publication date, aggregated by month.\n\nimport matplotlib.pyplot as plt\n\nvolume = rq4_volume_trend(clean, date_col=\"publication\", freq=\"M\")\nvolume.head()\n\n/Users/dallinrobinson/School/stat386/fbi-wanted-analysis/src/fbi_wanted_analysis/analysis.py:206: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n  out[\"period\"] = dt.dt.to_period(freq).dt.to_timestamp()\n\n\n\n\n\n\n\n\n\nperiod\nlistings\n\n\n\n\n0\n2010-07-01\n11\n\n\n1\n2010-08-01\n15\n\n\n2\n2010-09-01\n3\n\n\n3\n2010-10-01\n1\n\n\n4\n2012-03-01\n2\n\n\n\n\n\n\n\nColumns:\n\nperiod: start of the period (for example, first day of the month)\nlistings: number of listings in that period\n\nPlot it:\n\nplt.figure()\nplt.plot(volume[\"period\"], volume[\"listings\"])\nplt.xticks(rotation=45)\nplt.ylabel(\"Listings\")\nplt.title(\"Number of FBI Wanted Listings Over Time\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nThis gives a quick visual of whether the posting volume is stable, rising, or clustered in specific months.\nIf you want to work directly with snapshots and a snapshot_date column, you can also use quantity_over_time() instead of rq4_volume_trend() as long as your data frame includes that column.\n\n\n\n5.2 RQ2: Geographic concentration\nResearch Question 2 &gt; Which U.S. regions, states, or FBI field offices have the highest concentration of wanted cases, and how has this distribution shifted historically?\nThe analysis.py module includes a general helper, geographic_concentration_over_time, that expects a snapshot_date column and a geography column such as field_office or state. For simple work with the current pull, it is often easiest to summarize field offices directly from the cleaned data.\nBecause clean_wanted stores field_offices as a comma separated string, you can split and explode it to count offices.\n\ngeo_df = clean.copy()\n\n# Split comma separated field_offices into rows\ngeo_df[\"field_offices_list\"] = geo_df[\"field_offices\"].fillna(\"\").astype(str).str.split(\",\")\ngeo_df = geo_df.explode(\"field_offices_list\")\ngeo_df[\"field_offices_list\"] = geo_df[\"field_offices_list\"].str.strip()\ngeo_df = geo_df[geo_df[\"field_offices_list\"] != \"\"]\n\n# Top offices by count\ntop_offices = geo_df[\"field_offices_list\"].value_counts().head(15)\ntop_offices\n\nfield_offices_list\nwashingtondc    20\nlosangeles      17\nmiami            8\nsanfrancisco     6\nnewyork          5\nphiladelphia     5\nchicago          4\nseattle          4\ntampa            4\nhouston          4\nindianapolis     3\nsacramento       3\nminneapolis      3\nbuffalo          3\nneworleans       3\nName: count, dtype: int64\n\n\nYou can also combine this with time information by grouping on both publication and field_offices_list if you want a time series for each office.\n\ngeo_df[\"publication_month\"] = geo_df[\"publication\"].dt.to_period(\"M\").dt.to_timestamp()\noffice_time = (\n    geo_df.groupby([\"publication_month\", \"field_offices_list\"])[\"uid\"]\n    .nunique()\n    .reset_index(name=\"listings\")\n)\noffice_time.head()\n\n\n\n\n\n\n\n\npublication_month\nfield_offices_list\nlistings\n\n\n\n\n0\n2010-07-01\nnewyork\n1\n\n\n1\n2010-07-01\nwashingtondc\n10\n\n\n2\n2010-08-01\nbuffalo\n1\n\n\n3\n2010-08-01\nchicago\n1\n\n\n4\n2010-08-01\njackson\n1\n\n\n\n\n\n\n\nYou can then filter to a specific office of interest and plot its trend over time.\n\n\n\n5.3 RQ3: Reward amounts by crime type\nResearch Question 3 &gt; What types of crimes receive the highest reward amounts?\nUse reward_by_crime_type on the cleaned data.\n\nrq3 = reward_by_crime_type(clean)\nrq3.head(10)\n\n\n\n\n\n\n\n\ncrime_type\nmedian_reward\nmean_reward\nmax_reward\nlistings\n\n\n\n\n0\nCounterintelligence\n15000000.0\n15000000.0\n15000000\n2\n\n\n1\nMost Wanted Terrorists\n5000000.0\n4227777.777778\n5000000\n18\n\n\n2\nTen Most Wanted Fugitives\n5000000.0\n3750000.0\n10000000\n9\n\n\n3\nCyber's Most Wanted\n3500000.0\n4750000.0\n10000000\n4\n\n\n4\nCase of the Week\n250000.0\n250000.0\n250000\n1\n\n\n5\nAdditional Violent Crimes\n25000.0\n421000.0\n2000000\n5\n\n\n6\nViolent Crimes - Murders\n25000.0\n25000.0\n25000\n1\n\n\n7\nViolent Crime - Murders\n22500.0\n22500.0\n30000\n4\n\n\n8\nLaw Enforcement Assistance\n20000.0\n16666.666667\n25000\n3\n\n\n9\nCriminal Enterprise Investigations\n17500.0\n17500.0\n25000\n2\n\n\n\n\n\n\n\nThis returns:\n\ncrime_type: FBI subject tag\nmedian_reward: median of reward_amount_max_usd\nmean_reward: mean of reward_amount_max_usd\nmax_reward: maximum of reward_amount_max_usd\nlistings: number of listings that contributed to that row\n\nLook at the top crime types by median reward:\n\nrq3_top = rq3.sort_values(\"median_reward\", ascending=False).head(15)\nrq3_top\n\n\n\n\n\n\n\n\ncrime_type\nmedian_reward\nmean_reward\nmax_reward\nlistings\n\n\n\n\n0\nCounterintelligence\n15000000.0\n15000000.0\n15000000\n2\n\n\n1\nMost Wanted Terrorists\n5000000.0\n4227777.777778\n5000000\n18\n\n\n2\nTen Most Wanted Fugitives\n5000000.0\n3750000.0\n10000000\n9\n\n\n3\nCyber's Most Wanted\n3500000.0\n4750000.0\n10000000\n4\n\n\n4\nCase of the Week\n250000.0\n250000.0\n250000\n1\n\n\n5\nAdditional Violent Crimes\n25000.0\n421000.0\n2000000\n5\n\n\n6\nViolent Crimes - Murders\n25000.0\n25000.0\n25000\n1\n\n\n7\nViolent Crime - Murders\n22500.0\n22500.0\n30000\n4\n\n\n8\nLaw Enforcement Assistance\n20000.0\n16666.666667\n25000\n3\n\n\n9\nCriminal Enterprise Investigations\n17500.0\n17500.0\n25000\n2\n\n\n10\nSeeking Information\n17500.0\n23093.75\n100000\n16\n\n\n11\nCrimes Against Children\n10000.0\n10000.0\n10000\n1\n\n\n12\nIndian Country\n10000.0\n19166.666667\n75000\n6\n\n\n13\nKidnappings and Missing Persons\n10000.0\n847500.0\n5000000\n12\n\n\n14\nWhite-Collar Crime\n10000.0\n10000.0\n10000\n1\n\n\n\n\n\n\n\nPlot the top crime types:\n\nplt.figure()\nplt.barh(rq3_top[\"crime_type\"], rq3_top[\"median_reward\"])\nplt.gca().invert_yaxis()\nplt.xlabel(\"Median Reward (USD)\")\nplt.title(\"Top Crime Types by Median Reward\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nThis gives a direct view of which subject tags tend to be associated with higher rewards.\n\n\n\n5.4 RQ4: Trends in rewards and inferred priorities\nResearch Question 4 &gt; What do trends in rewards and quantity of wanted persons reveal about law enforcement priorities?\nFor this question the package includes several helper functions that look at:\n\nOverall volume of listings over time\nHow often rewards are offered\nHow large those rewards are\nWhere higher rewards cluster (by subject, by program, by field office)\n\n\n5.4.1 Reward trend over time\n\nreward_trend = rq4_reward_trend(clean, date_col=\"publication\", freq=\"M\")\nreward_trend.head()\n\n/Users/dallinrobinson/School/stat386/fbi-wanted-analysis/src/fbi_wanted_analysis/analysis.py:206: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n  out[\"period\"] = dt.dt.to_period(freq).dt.to_timestamp()\n\n\n\n\n\n\n\n\n\nperiod\nlistings\npct_with_reward_text\npct_with_numeric_reward\nmedian_reward_max_usd\np90_reward_max_usd\nmax_reward_max_usd\n\n\n\n\n0\n2010-07-01\n11\n100.000000\n100.000000\n5000000.0\n5000000.0\n5000000.0\n\n\n1\n2010-08-01\n15\n33.333333\n26.666667\n5000000.0\n5000000.0\n5000000.0\n\n\n2\n2010-09-01\n3\n66.666667\n33.333333\n50000.0\n50000.0\n50000.0\n\n\n3\n2010-10-01\n1\n0.000000\n0.000000\nNaN\nNaN\nNaN\n\n\n4\n2012-03-01\n2\n50.000000\n50.000000\n50000.0\n50000.0\n50000.0\n\n\n\n\n\n\n\nColumns include:\n\nperiod\nlistings\npct_with_reward_text\npct_with_numeric_reward\nmedian_reward_max_usd\np90_reward_max_usd\nmax_reward_max_usd\n\nYou can plot both prevalence and size.\n\nplt.figure()\nplt.plot(reward_trend[\"period\"], reward_trend[\"pct_with_reward_text\"], label=\"Reward text present\")\nplt.plot(reward_trend[\"period\"], reward_trend[\"pct_with_numeric_reward\"], label=\"Numeric reward present\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Percent of listings\")\nplt.title(\"Reward Prevalence Over Time\")\nplt.legend()\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nplt.figure()\nplt.plot(reward_trend[\"period\"], reward_trend[\"median_reward_max_usd\"], label=\"Median\")\nplt.plot(reward_trend[\"period\"], reward_trend[\"p90_reward_max_usd\"], label=\"P90\")\nplt.plot(reward_trend[\"period\"], reward_trend[\"max_reward_max_usd\"], label=\"Max\")\nplt.xticks(rotation=45)\nplt.ylabel(\"Reward max amount (USD)\")\nplt.title(\"Reward Size Over Time\")\nplt.legend()\nplt.tight_layout()\n\n\n\n\n\n\n\n\nThis lets you compare how many cases have rewards and how large those rewards are across time.\n\n\n5.4.2 Priority by subject\n\npriority_subject = rq4_priority_by_subject(clean, top_n=15)\npriority_subject\n\n\n\n\n\n\n\n\nsubject\nlistings\npct_numeric_reward\nmedian_reward_max_usd\n\n\n\n\n10\nSeeking Information\n22\n72.727273\n17500.0\n\n\n9\nMost Wanted Terrorists\n19\n94.736842\n5000000.0\n\n\n6\nKidnappings and Missing Persons\n17\n70.588235\n10000.0\n\n\n15\nViCAP Missing Persons\n14\n0.000000\nNaN\n\n\n2\nCrimes Against Children\n12\n8.333333\n10000.0\n\n\n4\nCyber's Most Wanted\n11\n36.363636\n3500000.0\n\n\n12\nTen Most Wanted Fugitives\n9\n100.000000\n5000000.0\n\n\n3\nCriminal Enterprise Investigations\n7\n28.571429\n17500.0\n\n\n0\nAdditional Violent Crimes\n5\n100.000000\n25000.0\n\n\n17\nViolent Crime - Murders\n5\n80.000000\n22500.0\n\n\n8\nLaw Enforcement Assistance\n5\n60.000000\n20000.0\n\n\n21\nWhite-Collar Crime\n5\n20.000000\n10000.0\n\n\n14\nViCAP Homicides and Sexual Assaults\n4\n0.000000\nNaN\n\n\n16\nViCAP Unidentified Persons\n3\n0.000000\nNaN\n\n\n19\nWhite Collar Crime\n3\n0.000000\nNaN\n\n\n\n\n\n\n\nColumns:\n\nsubject\nlistings\npct_numeric_reward\nmedian_reward_max_usd\n\nThis gives a simple proxy for “priority” by subject. Subjects that appear often and have higher numeric rewards look like higher priority categories in the data.\n\n\n5.4.3 Priority by program\n\npriority_program = rq4_priority_by_program(clean)\npriority_program\n\n\n\n\n\n\n\n\nreward_program\nlistings_with_text\nlistings_with_amount\nmedian_reward_max_usd\nmax_reward_max_usd\n\n\n\n\n0\nFBI\n49\n47\n20000.0\n250000.0\n\n\n2\nRewards for Justice\n22\n22\n5000000.0\n15000000.0\n\n\n3\nState Department\n8\n8\n4000000.0\n10000000.0\n\n\n1\nOther/Unknown\n1\n1\n5000000.0\n5000000.0\n\n\n\n\n\n\n\nColumns:\n\nreward_program\nlistings_with_text\nlistings_with_amount\nmedian_reward_max_usd\nmax_reward_max_usd\n\nThis is useful if you want to compare things like:\n\nHow many cases use FBI rewards\nHow many involve “Rewards for Justice”\nHow large the rewards tend to be for each program\n\n\n\n5.4.4 Priority by field office\n\npriority_office = rq4_priority_by_field_office(clean, top_n=15)\npriority_office\n\n\n\n\n\n\n\n\nfield_office\nlistings\npct_numeric_reward\nmedian_reward_max_usd\n\n\n\n\n0\nUnknown\n23\n0.000000\nNaN\n\n\n41\nwashingtondc\n20\n95.000000\n5000000.0\n\n\n18\nlosangeles\n17\n23.529412\n625000.0\n\n\n20\nmiami\n8\n25.000000\n1001250.0\n\n\n36\nsanfrancisco\n6\n100.000000\n25000.0\n\n\n26\nnewyork\n5\n60.000000\n5000000.0\n\n\n28\nphiladelphia\n5\n20.000000\n25000.0\n\n\n12\nhouston\n4\n100.000000\n4000000.0\n\n\n7\nchicago\n4\n50.000000\n15000.0\n\n\n37\nseattle\n4\n75.000000\n10000.0\n\n\n40\ntampa\n4\n25.000000\n5000.0\n\n\n25\nneworleans\n3\n100.000000\n20000.0\n\n\n32\nsacramento\n3\n33.333333\n20000.0\n\n\n5\nbuffalo\n3\n100.000000\n15000.0\n\n\n13\nindianapolis\n3\n33.333333\n10000.0\n\n\n\n\n\n\n\nColumns:\n\nfield_office\nlistings\npct_numeric_reward\nmedian_reward_max_usd\n\nHere you can see which field offices:\n\nHave the most listings in your pull\nHave higher rates of numeric rewards\nTend to have higher reward levels\n\nYou might pair this with maps or external context, but the function itself gives you a solid starting point."
  },
  {
    "objectID": "Tutorial.html#using-the-package-with-the-streamlit-app",
    "href": "Tutorial.html#using-the-package-with-the-streamlit-app",
    "title": "Getting Started with fbi_wanted_analysis",
    "section": "6. Using the package with the Streamlit app",
    "text": "6. Using the package with the Streamlit app\nThe repo also includes a streamlit_app.py file that builds an interactive dashboard on top of the same functions you have used here.\nIn a terminal, from the project root, run:\nstreamlit run src/fbi_wanted_analysis/streamlit_app.py\nThe app will:\n\nFetch and clean data using fetch_current_wanted and clean_wanted\nLet you filter by title, field office, sex, race, subjects, and reward presence\nShow:\n\nOverview metrics and a data preview\nVolume over time (RQ1)\nConcentration by field office (RQ2)\nReward amounts by crime type (RQ3)\nReward and volume trends, plus priority tables (RQ4)\n\n\nYou can compare the results you see in this notebook with the interactive charts in the app. Both use the same underlying functions."
  },
  {
    "objectID": "Tutorial.html#summary",
    "href": "Tutorial.html#summary",
    "title": "Getting Started with fbi_wanted_analysis",
    "section": "7. Summary",
    "text": "7. Summary\nThe fbi_wanted_analysis package gives you:\n\nA simple API wrapper: fetch_current_wanted\nA cleaning pipeline: clean_wanted\nReward parsing logic: parse_reward used inside the cleaning step\nAnalysis helpers for:\n\nVolume over time\nCrime types and rewards\nReward trends and inferred enforcement priorities\n\n\nYou can use it either in scripts and notebooks or through the Streamlit dashboard. For most custom analysis, the pattern is:\n\nFetch\nClean\nCall one or more helper functions\nVisualize or export the results"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "fbi_wanted_analysis",
    "section": "",
    "text": "Welcome to the homepage for fbi_wanted_analysis, a Python package built for STAT 386.\nThis package:\n\nPulls live data from the official FBI Wanted API\nCleans and standardizes the raw listings\nParses messy reward text into usable numeric amounts\nHelps you explore patterns in field offices, subjects, and rewards\n\nUse this site to learn how everything fits together and how to use the code in your own projects.\n\nRead the full function and module reference in the Documentation.\nWalk through a step-by-step example in the Getting Started Tutorial.\nSee the full analysis and research questions in the Technical Report."
  }
]